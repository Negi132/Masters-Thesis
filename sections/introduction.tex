\section{Introduction} \label{sec:introduction}

%\todo{Make abstract}
%\todo{NN summary table (tables of all the green lines. needs one more column to identify approach)}
%\todo{Collective summary table included in main (maybe make one of only row sums... sorry...)}
%\todo{Small general section about what gluon is within the implementation section}
%\todo{Whitespace issues (maybe) in results section}

The amount of reported money laundering in Denmark continues to rise year after year, with the vast majority of reports coming from financial institutions~\cite{hvidvasksekretariatetWebsite}. Institutions produce these reports by manually investigating potentially fraudulent transactions that have been flagged by their internal monitoring systems.

One problem with this system is that, due to the need for regulatory compliance, it is designed to flag too many transactions rather than too few~\cite{flagrightFalsePositives}. This results in the majority of work performed by \gls{aml} employees being spent investigating false positives created by the system. One of the biggest problems affecting AML detection methods is the quality of the data, namely the extreme class imbalance of datasets combined with the need for near perfect precision~\cite{jensen2023fightingmoneylaunderingstatistics}. In real world scenarios, imbalanced datasets are to be expected, but within \gls{aml} the majority of alarms are non fraudulent.

As an example of this, the real-world dataset used in this paper consists of $21{,}583$ alarms, while only $2{,}145$ of those were determined to be actual fraud, and $14{,}841$ were non fraudulent. That equates to a dataset imbalance of $87.37\%$ and $12.63\%$, respectively. This also excludes the currently active alarms that would skew the data more.

Additionally, due to the need for regulatory compliance, it is important for financial institutions to successfully detect truly fraudulent activity, as failure to do so may result in heavy fines placed upon the institution by regulatory bodies~\cite{amlFines}. As a by product of this, \gls{aml} employees spend a lot of time sifting through alarms in order to manually separate fraudulent from non fraudulent activity.

At the transaction level, industry reported false positive rates are typically in the range of $90$--$95\%$, meaning that the vast majority of transactions flagged by rule based monitoring systems do not correspond to confirmed fraud~\cite{amlFalsePositiveRate}. These false positive rates are for the alarm generation stage, where within millions of transactions that  they do not directly reflect the class balance of alarm level datasets used for investigation. Once alarms have been raised, the relevant task shifts from detecting suspicious transactions to prioritising already flagged alarms for manual review. It is this post alarm setting that is the focus of the present work.

This costs time, money, and effort that could be better spent investigating real fraudulent transactions, or anticipating and developing measures for emergent fraud patterns.

Much of the \gls{aml} research studies transaction level detection, where classification models predict whether individual transactions are suspicious or ordinary, often as an alternative to the rules-based systems that many financial institutions use to flag activity~\cite{jensen2023fightingmoneylaunderingstatistics, chen2018learning, kute2021deep, fan2025deeplearningapproachesantimoney, jullum2020detecting, namdar2025antimoneylaunderingmachinelearning}. In contrast, fewer studies consider the downstream setting in which an institution has already raised alarms and the task is to classify or triage these pre-raised alerts using the information available at investigation time. This is partly explained by the sensitivity of transaction data and the practical difficulty of obtaining real-world alarm datasets.

In this work, we study post alarm classification as a decision support task. Rather than changing the upstream detection system, we focus on classifying alarms that have already been raised, with the goal of reducing the time and effort \gls{aml} employees spend investigating false positives.

One of the few papers that explicitly studies classification of pre-raised alarms~\cite{Bakry2024AutomaticSuppressionAML} proposes an approach that allows approximately $13\%$ of suspicious transactions to go undetected. As in~\cite{Bakry2024AutomaticSuppressionAML}, we focus on transactions that have already been flagged by the bank's internal systems.

To support this, we obtained access to internal alarm data through a collaboration with \gls{lsb}, a Danish bank. The bank primarily handles personal banking, which is reflected in the provided data.

Another important circumstance is that L\&SB recently
reworked their entire internal alarm system, leading to the
obsoletion of data from before January 1st 2025. This results in
smaller amounts of data being acquired than would otherwise
ordinarily be available.

Given the limited dataset size, we evaluate false positive reduction using traditional classification approaches that are less sensitive to small sample sizes. We then benchmark several modelling strategies, including monolithic models, ensembles, \glspl{nn}, \glspl{vc}, and AutoGluon, to assess whether any approach can achieve performance sufficient to reduce the workload of \gls{aml} employees.

%While no model achieved the perfect precision or recall needed for complete compliance with regulatory commitments, there were multiple options that could be utilised by \gls{lsb} to perform a rough sorting of alarms into high and low priority alarms, letting \gls{aml} employees better focus their efforts.

The remainder of the paper is organized as follows. Section~\ref{sec:related-works} reviews related work on AML classification. Section~\ref{sec:problem-formulation-and-approach} presents the problem formulation and describes the AML workflow considered in this study. Section~\ref{sec:data_preprocessing} details the data and the preprocessing approach. Section~\ref{sec:experiments} explains the modelling approaches taken in this study. Section~\ref{sec:experiments} describes the evaluation methodology and experimental setup. Section~\ref{sec:results} presents the results, and Section~\ref{sec:conclusion&future-works} finishes with the paper and outlines directions for future work.
