\section{Data and Preprocessing}\label{sec:data_preprocessing}

This section describes the datasets, the label definition used for
supervised learning, and the preprocessing steps used to construct a single
alarms training dataset.

\subsection{Data Sources}\label{sec:data_sources}
All tables provided by L\aa n \& Spar Bank span the period from January 1, 2025
to September 30, 2025, and are pseudonymized. The raw tables used in this study
are:
\begin{enumerate}
%	\item \textbf{Transactions}: Detailing all transactions made by the
%	bank's customers throughout the period. Includes trans
%	action sources, destinations, amounts, etc.
	\item \textbf{Alarms}: Details all alarms raised by the automatic
	flagging system. Includes current alarm status, associated
	account, ID of the AML employee handling the alarm,
	internal account designations, etc.
	\item \textbf{Alarm Events}: Shows all actions taken related to a
	specific alarm. The same alarm ID may appear multiple
	times in this table if, for example, an AML employee
	has first requested documentation for the case from the
	account holder, then added documentation when the
	account holder has provided it, then closed the alarm.
	\item \textbf{Customers}: General customer information such as age,
	place of residence, marital status, etc.
	\item \textbf{Other tables}: Supplementary tables that are only
	used for connecting connecting Customers to Alarms.
\end{enumerate}

Table~\ref{tab:raw_data_summary} summarizes the raw table sizes and
Table~\ref{tab:alarm_label_summary} summarizes alarm label counts.

\begin{table}[t]
	\centering
	\begin{tabular}{p{0.60\linewidth} r}
		\toprule
		Description & Count \\
		\midrule
		Customers & 420{,}982 \\
		Alarms & 21{,}583 \\
		Alarm Events & 42{,}765 \\
		\bottomrule
	\end{tabular}
	\caption{Data summary for the raw dataset}
	\label{tab:raw_data_summary}
\end{table}

\begin{table}[t]
	\centering
	\begin{tabular}{p{0.60\linewidth} r}
		\toprule
		Label & Count \\
		\midrule
		CLOSED & 14{,}841 \\
		ADDED & 2{,}145 \\
		ACTIVE & 4{,}597 \\
		\bottomrule
	\end{tabular}
	\caption{Alarm label counts in the raw dataset}
	\label{tab:alarm_label_summary}
\end{table}

\subsection{Labels and Data Instances}\label{sec:labels_unit}
Each data instance corresponds to a single alarm. Each alarm is associated with
a final investigation outcome which is what the models will be trying to predict
, either \textit{CLOSED} or \textit{ADDED TO CASE}. We refer
to the latter simply as \textit{ADDED}. \textit{CLOSED} indicates that the alarm
was resolved as a false positive, while \textit{ADDED} indicates that the bank
could not rule out suspicious activity. A third label, \textit{ACTIVE}, 
is used for ongoing investigations and is always
temporary. We discard alarms with this label because they do not yet have a 
final outcome.


\subsection{Dataset Construction}\label{sec:dataset_construction}
We construct a single alarm-level dataset by consolidating the relevant source
tables into one row per alarm, joining alarm metadata with customer attributes
and derived information from alarm events where applicable.

We exclude alarm rows that are not suitable for training, including:
\begin{itemize}
	\item \textbf{Manual alarms}: that are not raised by the rules-based system:
	These lack supporting data explaining why they
	were raised.
	\item \textbf{Alarms closed due to rule revisions} that reflect process changes rather than underlying
	alert/transaction behavior.
	\item \textbf{Rows with null values}. We focus only on transactions
	that triggered the internal alarm system, so incomplete
	records were dropped.
\end{itemize}
After applying these criteria (and discarding \textit{ACTIVE} alarms), the final
alarm-level dataset contains $7{,}634$ alarms.

\subsection{Preprocessing and Feature Engineering}\label{sec:preprocessing}
Each raw dataset is cleaned and prepared independently and relevant datasets which 
were determined to be Alarms, Customers and Alarm events were joined to produce a single dataset.


\paragraph{\textbf{Feature Selection}}
Exploratory analysis identified features
that contributed no useful information. These features were
either IDs or static values or duplicates of other columns.
Alarms had 21 such features, while customers had 13 such
features. These features were removed before model training.
After transforming and pruning, the training dataset contained
around 19 feature columns.

\paragraph{\textbf{Target Label Preprocessing}}
\label{subsec:prerocesing_labels}
Initially only the final label of an alarm was used for classification. However, after a discussion with \gls{lsb}, they requested that if an alarm had ever been investigated at all by a human, i.e., if an alarm ever had any of the before-mentioned interim-label, then they would like the system to detect such alarms. These modifications to the dataset were insignificant and only two rows were impacted which made no difference with the current data but might be of use in the future.

\paragraph{\textbf{Feature Engineering and Encoding}}
Feature construction followed
established practices for tabular modeling. Continuous variables
such as Risk Score were scaled where appropriate to mitigate
difference in magnitude, categorical variables were one hot
encoded, and datetime fields such as the date since the customer
has been active to number of days since they have been active
for have been converted to days and birthday has been converted
to age.

\paragraph{\textbf{Implementation Note}}
Data processing is implemented in Python, using Polars for most transformation and 
loading steps and Pandas for quick inspection and validation.

\subsection{Transaction Linkage and Scope}\label{sec:transaction_linkage}
As with other reasearch in AML fraud detectiong we were also given accesss to transactions 
There was no clear way to connect them. The best approach was to use some information (such as 
using the alarm timestamp, total alarm amount, and the bank days mentioned) associated with some
alarms to guess the associated transactions. Only around 70\% of the $7{,}634$ alarms were 
theoretically linkable. We were informed that additional payment-processing data from Netcompany Banking
Services might enable more reliable alarm to transaction linkage, but this data
is not available to us. Given this limited scope of connection we do not 
train a transaction-level dataset in this study.
