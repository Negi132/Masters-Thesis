\onecolumn
\subsection{\glspl{mm}, \glspl{ee}, and \glspl{ce}
	Performance}\label{app:C}
\definecolor{monoRow}{RGB}{255,210,210} % stronger light red
\definecolor{empRow}{RGB}{205,225,255}  % stronger soft blue
\definecolor{catRow}{RGB}{205,255,205}  % stronger soft green

\subsubsection{\glspl{mm}, \glspl{ee}, and \glspl{ce} Performance on Raw
	\textit{ADDED / CLOSED} Classification Split}
\begin{longtable}{lllrrrrrr}
	\caption{Performance of classifiers on a dataset where the only two labels 
		considered were the \textit{CLOSED} and \textit{ADDED} labels. Rows 
		shaded 
		in light red correspond
		to \colorbox{monoRow}{\texttt{mono}}, light blue to 
		\colorbox{empRow}{\texttt{employee\_ensemble}}, and light
		green to \colorbox{catRow}{\texttt{category\_ensemble}}. Cells 
		highlighted with dark green 
		are the highest
		values in the column. Cells highlighted with dark red are the lowest 
		values in the column. The \textit{Scorer} column refers to what the 
		specific row was optimising for.}
	\label{tab:final_olddata}\\
	
	\toprule
	& & \multicolumn{2}{c}{Recall} & \multicolumn{2}{c}{Precision} & & \\
	\cmidrule(lr){3-4} \cmidrule(lr){5-6}
	Base Classifier & Scorer & Added & Closed &
	Added & Closed & Accuracy & F1\\
	\midrule
	\endfirsthead
	
	\toprule
	& & \multicolumn{2}{c}{Recall} & \multicolumn{2}{c}{Precision} & & \\
	\cmidrule(lr){3-4} \cmidrule(lr){5-6}
	Base Classifier & Scorer & Added & Closed &
	Added & Closed & Accuracy & F1\\
	\midrule
	\endhead
	
	\midrule
	\multicolumn{9}{r}{\emph{Continued on next page}}\\
	\endfoot
	
	\bottomrule
	\endlastfoot
	
	\rowcolor{monoRow}
	LogisticRegression & recall\_closed & 0.788 & 0.671 & 0.958 &
	0.252 & 0.686 & 0.381\\
	\rowcolor{empRow}
	LogisticRegression & recall\_closed & 0.700 &
	0.471 & 0.157 & 0.918 & 0.500 & 0.256\\
	\rowcolor{catRow}
	LogisticRegression & recall\_closed & 0.872 &
	0.330 & 0.154 & 0.948 & 0.397 & 0.262\\
	\rowcolor{monoRow}
	LogisticRegression & precision\_closed & 0.717 & 0.774 & 0.951 &
	0.308 & 0.767 & 0.431\\
	\rowcolor{empRow}
	LogisticRegression & precision\_closed & 0.145 &
	0.962 & 0.350 & 0.889 & 0.862 & 0.205\\
	\rowcolor{catRow}
	LogisticRegression & precision\_closed & 0.310 &
	0.882 & 0.270 & 0.901 & 0.812 & 0.288\\
	\rowcolor{monoRow}
	LogisticRegression & recall\_add & 0.774 & 0.717 & 0.308 & 0.951
	& 0.767 & 0.431\\
	\rowcolor{empRow}
	LogisticRegression & recall\_add & 0.963 & 0.155 &
	0.890 & 0.371 & 0.864 & 0.219\\
	\rowcolor{catRow}
	LogisticRegression & recall\_add & 0.885 & 0.300 &
	0.900 & 0.267 & 0.813 & 0.283\\
	\rowcolor{monoRow}
	LogisticRegression & precision\_add & 0.715 & 0.788 & 0.280 &
	0.960 & 0.724 & 0.413\\
	\rowcolor{empRow}
	LogisticRegression & precision\_add & 0.533 &
	0.670 & 0.920 & 0.168 & 0.550 & 0.268\\
	\rowcolor{catRow}
	LogisticRegression & precision\_add & 0.831 &
	0.438 & 0.913 & 0.267 & 0.783 & 0.332\\
	\rowcolor{monoRow}
	LogisticRegression & accuracy & 0.717 & 0.774 & 0.951 & 0.308 &
	0.767 & 0.431\\
	\rowcolor{empRow}
	LogisticRegression & accuracy & 0.104 & 0.969 &
	0.323 & 0.885 & 0.863 & 0.158\\
	\rowcolor{catRow}
	LogisticRegression & accuracy & 0.286 & 0.888 &
	0.264 & 0.899 & 0.814 & 0.275\\
	\rowcolor{monoRow}
	LogisticRegression & f1 & 0.717 & 0.774 & 0.951 & 0.308 & 0.767
	& 0.431\\
	\rowcolor{empRow}
	LogisticRegression & f1 & 0.219 & 0.930 & 0.304 &
	0.895 & 0.842 & 0.254\\
	\rowcolor{catRow}
	LogisticRegression & f1 & 0.384 & 0.846 & 0.259 &
	0.907 & 0.789 & 0.309\\
	\rowcolor{monoRow}
	KNeighborsClassifier & recall\_closed & 0.835 & 0.816 & 0.972 &
	0.389 & 0.818 & 0.530\\
	\rowcolor{empRow}
	KNeighborsClassifier & recall\_closed & 0.562 &
	0.687 & 0.201 & 0.918 & 0.672 & 0.297\\
	\rowcolor{catRow}
	KNeighborsClassifier & recall\_closed & 0.781 &
	0.363 & 0.147 & 0.922 & 0.415 & 0.247\\
	\rowcolor{monoRow}
	KNeighborsClassifier & precision\_closed & 0.754 & 0.908 & 0.963
	& 0.536 & 0.889 & 0.627\\
	\rowcolor{empRow}
	KNeighborsClassifier & precision\_closed & 0.239 &
	0.909 & 0.270 & 0.895 & 0.827 & 0.254\\
	\rowcolor{catRow}
	KNeighborsClassifier & precision\_closed & 0.545 &
	0.703 & 0.205 & 0.917 & 0.684 & 0.298\\
	\rowcolor{monoRow}
	KNeighborsClassifier & recall\_add & 0.908 & 0.754 & 0.536 &
	0.963 & 0.889 & 0.627\\
	\rowcolor{empRow}
	KNeighborsClassifier & recall\_add & 0.929 & 0.205
	& 0.893 & 0.288 & 0.840 & 0.240\\
	\rowcolor{catRow}
	KNeighborsClassifier & recall\_add & 0.806 & 0.380
	& 0.903 & 0.216 & 0.754 & 0.276\\
	\rowcolor{monoRow}
	KNeighborsClassifier & precision\_add & 0.816 & 0.835 & 0.389 &
	0.972 & 0.818 & 0.530\\
	\rowcolor{empRow}
	KNeighborsClassifier & precision\_add & 0.721 &
	0.549 & 0.919 & 0.216 & 0.700 & 0.310\\
	\rowcolor{catRow}
	KNeighborsClassifier & precision\_add & 0.476 &
	0.704 & 0.920 & 0.159 & 0.504 & 0.259\\
	\rowcolor{monoRow}
	KNeighborsClassifier & accuracy & 0.754 & 0.908 & 0.963 & 0.536
	& 0.889 & 0.627\\
	\rowcolor{empRow}
	KNeighborsClassifier & accuracy & 0.205 & 0.929 &
	0.288 & 0.893 & 0.840 & 0.240\\
	\rowcolor{catRow}
	KNeighborsClassifier & accuracy & 0.337 & 0.836 &
	0.223 & 0.900 & 0.774 & 0.268\\
	\rowcolor{monoRow}
	KNeighborsClassifier & f1 & 0.754 & 0.908 & 0.963 & 0.536 &
	0.889 & 0.627\\
	\rowcolor{empRow}
	KNeighborsClassifier & f1 & 0.411 & 0.840 & 0.265
	& 0.910 & 0.787 & 0.322\\
	\rowcolor{catRow}
	KNeighborsClassifier & f1 & 0.596 & 0.652 & 0.194
	& 0.920 & 0.645 & 0.292\\
	\rowcolor{monoRow}
	GaussianNB & recall\_closed & 0.865 & 0.450 & 0.960 & 0.181 &
	0.501 & 0.299\\
	\rowcolor{empRow}
	GaussianNB & recall\_closed & 0.051 & 0.990 &
	0.405 & 0.881 & 0.874 & 0.090\\
	\rowcolor{catRow}
	GaussianNB & recall\_closed & 0.300 & 0.811 &
	0.182 & 0.892 & 0.748 & 0.226\\
	\rowcolor{monoRow}
	GaussianNB & precision\_closed & 0.865 & 0.450 & 0.960 & 0.181 &
	0.501 & 0.299\\
	\rowcolor{empRow}
	GaussianNB & precision\_closed & 0.051 & 0.990 &
	0.405 & 0.881 & 0.874 & 0.090\\
	\rowcolor{catRow}
	GaussianNB & precision\_closed & 0.300 & 0.811 &
	0.182 & 0.892 & 0.748 & 0.226\\
	\rowcolor{monoRow}
	GaussianNB & recall\_add & 0.450 & 0.865 & 0.181 & 0.960 & 0.501
	& 0.299\\
	\rowcolor{empRow}
	GaussianNB & recall\_add & 0.990 & 0.051 & 0.881 &
	0.405 & 0.874 & 0.090\\
	\rowcolor{catRow}
	GaussianNB & recall\_add & 0.811 & 0.300 & 0.892 &
	0.182 & 0.748 & 0.226\\
	\rowcolor{monoRow}
	GaussianNB & precision\_add & 0.450 & 0.865 & 0.181 & 0.960 &
	0.501 & 0.299\\
	\rowcolor{empRow}
	GaussianNB & precision\_add & 0.990 & 0.051 &
	0.881 & 0.405 & 0.874 & 0.090\\
	\rowcolor{catRow}
	GaussianNB & precision\_add & 0.811 & 0.300 &
	0.892 & 0.182 & 0.748 & 0.226\\
	\rowcolor{monoRow}
	GaussianNB & accuracy & 0.865 & 0.450 & 0.960 & 0.181 & 0.501 &
	0.299\\
	\rowcolor{empRow}
	GaussianNB & accuracy & 0.051 & 0.990 & 0.405 &
	0.881 & 0.874 & 0.090\\
	\rowcolor{catRow}
	GaussianNB & accuracy & 0.300 & 0.811 & 0.182 &
	0.892 & 0.748 & 0.226\\
	\rowcolor{monoRow}
	GaussianNB & f1 & 0.865 & 0.450 & 0.960 & 0.181 & 0.501 & 0.299\\
	\rowcolor{empRow}
	GaussianNB & f1 & 0.051 & 0.990 & 0.405 & 0.881 &
	0.874 & 0.090\\
	\rowcolor{catRow}
	GaussianNB & f1 & 0.300 & 0.811 & 0.182 & 0.892 &
	0.748 & 0.226\\
	\rowcolor{monoRow}
	DecisionTreeClassifier & recall\_closed & 0.987 & 0.211 &
	\bestcell{0.991} & 0.149 & 0.307 & 0.259\\
	\rowcolor{empRow}
	DecisionTreeClassifier & recall\_closed & 0.330 &
	0.833 & 0.217 & 0.899 & 0.771 & 0.262\\
	\rowcolor{catRow}
	DecisionTreeClassifier & recall\_closed & 0.902 &
	0.188 & \worstcell{0.135} & 0.932 & \worstcell{0.276} & 0.235\\
	\rowcolor{monoRow}
	DecisionTreeClassifier & precision\_closed & 0.606 & 0.929 &
	0.944 & 0.545 & 0.889 & 0.574\\
	\rowcolor{empRow}
	DecisionTreeClassifier & precision\_closed & 0.111
	& 0.948 & 0.229 & 0.884 & 0.845 & 0.150\\
	\rowcolor{catRow}
	DecisionTreeClassifier & precision\_closed & 0.236
	& 0.894 & 0.238 & 0.893 & 0.813 & 0.237\\
	\rowcolor{monoRow}
	DecisionTreeClassifier & recall\_add & 0.929 & 0.616 & 0.550 &
	0.945 & 0.891 & 0.581\\
	\rowcolor{empRow}
	DecisionTreeClassifier & recall\_add & 0.966 &
	0.074 & 0.881 & 0.234 & 0.856 & 0.113\\
	\rowcolor{catRow}
	DecisionTreeClassifier & recall\_add & 0.900 &
	0.239 & 0.894 & 0.251 & 0.819 & 0.245\\
	\rowcolor{monoRow}
	DecisionTreeClassifier & precision\_add & 0.211 & 0.987 & 0.149
	& 0.991 & 0.307 & 0.259\\
	\rowcolor{empRow}
	DecisionTreeClassifier & precision\_add & 0.889 &
	0.189 & 0.887 & 0.193 & 0.803 & 0.191\\
	\rowcolor{catRow}
	DecisionTreeClassifier & precision\_add & 0.389 &
	0.754 & 0.919 & \worstcell{0.148} & 0.434 & 0.247\\
	\rowcolor{monoRow}
	DecisionTreeClassifier & accuracy & 0.613 & 0.929 & 0.945 &
	0.548 & 0.890 & 0.579\\
	\rowcolor{empRow}
	DecisionTreeClassifier & accuracy & 0.111 & 0.958
	& 0.273 & 0.885 & 0.854 & 0.158\\
	\rowcolor{catRow}
	DecisionTreeClassifier & accuracy & 0.327 & 0.869
	& 0.259 & 0.902 & 0.802 & 0.289\\
	\rowcolor{monoRow}
	DecisionTreeClassifier & f1 & 0.633 & 0.922 & 0.947 & 0.531 &
	0.886 & 0.578\\
	\rowcolor{empRow}
	DecisionTreeClassifier & f1 & 0.108 & 0.954 &
	0.246 & 0.884 & 0.850 & 0.150\\
	\rowcolor{catRow}
	DecisionTreeClassifier & f1 & 0.313 & 0.907 &
	0.321 & 0.904 & 0.834 & 0.317\\
	\rowcolor{monoRow}
	RandomForestClassifier & recall\_closed & 0.983 & 0.251 & 0.991
	& 0.156 & 0.341 & 0.269\\
	\rowcolor{empRow}
	RandomForestClassifier & recall\_closed & 0.721 &
	0.498 & 0.168 & 0.927 & 0.525 & 0.272\\
	\rowcolor{catRow}
	RandomForestClassifier & recall\_closed & 0.508 &
	0.565 & 0.141 & 0.891 & 0.558 & 0.221\\
	\rowcolor{monoRow}
	RandomForestClassifier & precision\_closed & 0.545 & 0.990 &
	0.939 & 0.880 & \bestcell{0.935} & \bestcell{0.674}\\
	\rowcolor{empRow}
	RandomForestClassifier & precision\_closed &
	\worstcell{0.017} & 0.994 & 0.278 & 0.878 & 0.874 & 0.032\\
	\rowcolor{catRow}
	RandomForestClassifier & precision\_closed & 0.141
	& 0.984 & 0.560 & 0.891 & 0.881 & 0.226\\
	\rowcolor{monoRow}
	RandomForestClassifier & recall\_add & 0.990 & 0.539 & 0.879 &
	0.939 & 0.934 & 0.668\\
	\rowcolor{empRow}
	RandomForestClassifier & recall\_add & 0.997 &
	\worstcell{0.010} & 0.878 & 0.300 & 0.875 & \worstcell{0.020}\\
	\rowcolor{catRow}
	RandomForestClassifier & recall\_add &
	\bestcell{1.000} & 0.081 & 0.886 & \bestcell{1.000} & 0.887 & 0.150\\
	\rowcolor{monoRow}
	RandomForestClassifier & precision\_add & 0.193 & 0.983 & 0.146
	& 0.988 & 0.290 & 0.254\\
	\rowcolor{empRow}
	RandomForestClassifier & precision\_add & 0.547 &
	0.673 & 0.923 & 0.173 & 0.563 & 0.275\\
	\rowcolor{catRow}
	RandomForestClassifier & precision\_add & 0.602 &
	0.579 & 0.911 & 0.170 & 0.599 & 0.262\\
	\rowcolor{monoRow}
	RandomForestClassifier & accuracy & 0.539 & 0.988 & 0.939 &
	0.865 & 0.933 & 0.664\\
	\rowcolor{empRow}
	RandomForestClassifier & accuracy & 0.020 & 0.996
	& 0.400 & 0.879 & 0.876 & 0.038\\
	\rowcolor{catRow}
	RandomForestClassifier & accuracy & 0.108 &
	\bestcell{0.999} & 0.941 & 0.889 & 0.889 & 0.193\\
	\rowcolor{monoRow}
	RandomForestClassifier & f1 & 0.576 & 0.981 & 0.943 & 0.810 &
	0.931 & 0.673\\
	\rowcolor{empRow}
	RandomForestClassifier & f1 & 0.047 & 0.979 &
	0.241 & 0.880 & 0.865 & 0.079\\
	\rowcolor{catRow}
	RandomForestClassifier & f1 & 0.205 & 0.961 &
	0.427 & 0.896 & 0.868 & 0.277\\
	\rowcolor{monoRow}
	HistGradientBoostingClassifier & recall\_closed & 0.936 & 0.469
	& 0.981 & 0.198 & 0.526 & 0.327\\
	\rowcolor{empRow}
	HistGradientBoostingClassifier & recall\_closed &
	0.391 & 0.817 & 0.230 & 0.905 & 0.764 & 0.290\\
	\rowcolor{catRow}
	HistGradientBoostingClassifier & recall\_closed &
	0.535 & 0.642 & 0.173 & 0.908 & 0.629 & 0.262\\
	\rowcolor{monoRow}
	HistGradientBoostingClassifier & precision\_closed & 0.744 &
	0.868 & 0.960 & 0.442 & 0.853 & 0.555\\
	\rowcolor{empRow}
	HistGradientBoostingClassifier & precision\_closed
	& 0.024 & 0.989 & 0.233 & 0.878 & 0.870 & 0.043\\
	\rowcolor{catRow}
	HistGradientBoostingClassifier & precision\_closed
	& 0.279 & 0.908 & 0.300 & 0.900 & 0.831 & 0.289\\
	\rowcolor{monoRow}
	HistGradientBoostingClassifier & recall\_add & 0.866 & 0.731
	& 0.434 & 0.958 & 0.850 & 0.545\\
	\rowcolor{empRow}
	HistGradientBoostingClassifier & recall\_add &
	0.992 & 0.020 & 0.878 & 0.261 & 0.872 & 0.037\\
	\rowcolor{catRow}
	HistGradientBoostingClassifier & recall\_add &
	0.989 & 0.081 & 0.885 & 0.511 & 0.877 & 0.140\\
	\rowcolor{monoRow}
	HistGradientBoostingClassifier & precision\_add & 0.431 & 0.953
	& 0.190 & 0.985 & 0.495 & 0.317\\
	\rowcolor{empRow}
	HistGradientBoostingClassifier & precision\_add &
	0.869 & 0.323 & 0.901 & 0.257 & 0.802 & 0.286\\
	\rowcolor{catRow}
	HistGradientBoostingClassifier & precision\_add &
	0.873 & 0.266 & 0.895 & 0.228 & 0.799 & 0.245\\
	\rowcolor{monoRow}
	HistGradientBoostingClassifier & accuracy & 0.737 & 0.858
	& 0.959 & 0.421 & 0.843 & 0.536\\
	\rowcolor{empRow}
	HistGradientBoostingClassifier & accuracy & 0.024
	& 0.991 & 0.280 & 0.879 & 0.872 & 0.043\\
	\rowcolor{catRow}
	HistGradientBoostingClassifier & accuracy & 0.118
	& 0.988 & 0.574 & 0.889 & 0.881 & 0.196\\
	\rowcolor{monoRow}
	HistGradientBoostingClassifier & f1 & 0.731 & 0.872 & 0.958 &
	0.444 & 0.854 & 0.552\\
	\rowcolor{empRow}
	HistGradientBoostingClassifier & f1 & 0.172 &
	0.946 & 0.307 & 0.891 & 0.850 & 0.220\\
	\rowcolor{catRow}
	HistGradientBoostingClassifier & f1 & 0.290 &
	0.901 & 0.291 & 0.900 & 0.826 & 0.290\\
	\rowcolor{monoRow}
	XGBClassifier & recall\_closed & 0.869 & 0.601 & 0.970 & 0.234 &
	0.634 & 0.369\\
	\rowcolor{empRow}
	XGBClassifier & recall\_closed & 0.189 & 0.939 &
	0.303 & 0.892 & 0.847 & 0.232\\
	\rowcolor{catRow}
	XGBClassifier & recall\_closed & 0.101 & 0.949 &
	0.216 & 0.883 & 0.844 & 0.138\\
	\rowcolor{monoRow}
	XGBClassifier & precision\_closed & 0.734 & 0.869 & 0.959 &
	0.440 & 0.853 & 0.551\\
	\rowcolor{empRow}
	XGBClassifier & precision\_closed & 0.111 & 0.967 &
	0.324 & 0.886 & 0.862 & 0.165\\
	\rowcolor{catRow}
	XGBClassifier & precision\_closed & 0.057 & 0.995 &
	0.607 & 0.883 & 0.879 & 0.105\\
	\rowcolor{monoRow}
	XGBClassifier & recall\_add & 0.869 & 0.734 & 0.440 & 0.959 &
	0.853 & 0.551\\
	\rowcolor{empRow}
	XGBClassifier & recall\_add & 0.968 & 0.104 &
	0.885 & 0.316 & 0.862 & 0.157\\
	\rowcolor{catRow}
	XGBClassifier & recall\_add & 0.992 & 0.044 &
	0.881 & 0.448 & 0.876 & 0.080\\
	\rowcolor{monoRow}
	XGBClassifier & precision\_add & 0.601 & 0.869 & 0.234 & 0.970 &
	0.634 & 0.369\\
	\rowcolor{empRow}
	XGBClassifier & precision\_add & 0.960 & 0.128 &
	0.887 & 0.311 & 0.858 & 0.181\\
	\rowcolor{catRow}
	XGBClassifier & precision\_add & 0.963 & 0.081 &
	0.882 & 0.233 & 0.854 & 0.120\\
	\rowcolor{monoRow}
	XGBClassifier & accuracy & 0.734 & 0.869 & 0.959 & 0.440 & 0.853
	& 0.551\\
	\rowcolor{empRow}
	XGBClassifier & accuracy & 0.118 & 0.975 & 0.398 &
	0.887 & 0.870 & 0.182\\
	\rowcolor{catRow}
	XGBClassifier & accuracy & 0.051 & 0.995 & 0.600 &
	0.882 & 0.879 & 0.093\\
	\rowcolor{monoRow}
	XGBClassifier & f1 & 0.734 & 0.869 & 0.959 & 0.440 & 0.853 &
	0.551\\
	\rowcolor{empRow}
	XGBClassifier & f1 & 0.114 & 0.969 & 0.343 & 0.886 &
	0.864 & 0.172\\
	\rowcolor{catRow}
	XGBClassifier & f1 & 0.037 & 0.988 & 0.297 & 0.880 &
	0.871 & 0.066\\
	\rowcolor{monoRow}
	LGBMClassifier & recall\_closed & 0.795 & 0.783 & 0.964 & 0.339
	& 0.784 & 0.475\\
	\rowcolor{empRow}
	LGBMClassifier & recall\_closed & 0.104 & 0.966 &
	0.301 & 0.885 & 0.860 & 0.155\\
	\rowcolor{catRow}
	LGBMClassifier & recall\_closed & 0.697 & 0.528 &
	0.172 & 0.925 & 0.549 & 0.275\\
	\rowcolor{monoRow}
	LGBMClassifier & precision\_closed & 0.768 & 0.847 & 0.963 &
	0.414 & 0.838 & 0.538\\
	\rowcolor{empRow}
	LGBMClassifier & precision\_closed & 0.064 & 0.971 &
	0.235 & 0.881 & 0.859 & 0.101\\
	\rowcolor{catRow}
	LGBMClassifier & precision\_closed & 0.596 & 0.663 &
	0.199 & 0.921 & 0.655 & 0.298\\
	\rowcolor{monoRow}
	LGBMClassifier & recall\_add & 0.847 & 0.768 & 0.414 & 0.963 &
	0.838 & 0.538\\
	\rowcolor{empRow}
	LGBMClassifier & recall\_add & 0.980 & 0.064 & 0.882 &
	0.311 & 0.867 & 0.106\\
	\rowcolor{catRow}
	LGBMClassifier & recall\_add & 0.689 & 0.582 & 0.922 &
	0.208 & 0.676 & 0.306\\
	\rowcolor{monoRow}
	LGBMClassifier & precision\_add & 0.783 & 0.795 & 0.339 & 0.964 &
	0.784 & 0.475\\
	\rowcolor{empRow}
	LGBMClassifier & precision\_add & 0.968 & 0.098 & 0.884 &
	0.302 & 0.861 & 0.148\\
	\rowcolor{catRow}
	LGBMClassifier & precision\_add & 0.643 & 0.613 & 0.922 &
	0.194 & 0.640 & 0.295\\
	\rowcolor{monoRow}
	LGBMClassifier & accuracy & 0.768 & 0.847 & 0.963 & 0.414 &
	0.838 & 0.538\\
	\rowcolor{empRow}
	LGBMClassifier & accuracy & 0.067 & 0.974 & 0.270 &
	0.882 & 0.863 & 0.108\\
	\rowcolor{catRow}
	LGBMClassifier & accuracy & 0.582 & 0.689 & 0.208 &
	0.922 & 0.676 & 0.306\\
	\rowcolor{monoRow}
	LGBMClassifier & f1 & 0.768 & 0.847 & 0.963 & 0.414 & 0.838 &
	0.538\\
	\rowcolor{empRow}
	LGBMClassifier & f1 & 0.094 & 0.972 & 0.318 & 0.884 &
	0.864 & 0.145\\
	\rowcolor{catRow}
	LGBMClassifier & f1 & 0.596 & 0.661 & 0.198 & 0.921 &
	0.653 & 0.297\\
\end{longtable}
\newpage
\subsubsection{\glspl{mm}, \glspl{ee}, and \glspl{ce} Performance on Modified
	\textit{ADDED / CLOSED} Classification Split}
\begin{longtable}{llrrrrrr}
	\caption{Performance of classifiers on a dataset where all alarms that were 
		previously investigated by a human, i.e. previously has had a label 
		other 
		than \textit{ACTIVE} or \textit{CLOSED}, has been treated as if their 
		label 
		is 
		\textit{ADDED}. Rows shaded in light red correspond
		to \colorbox{monoRow}{\texttt{mono}}, light blue to
		\colorbox{empRow}{\texttt{employee\_ensemble}}, and light
		green to \colorbox{catRow}{\texttt{category\_ensemble}}. Cells 
		highlighted with dark green
		are the highest values in the column. Cells highlighted with dark red 
		are the lowest values in the column. The \textit{Scorer} column refers 
		to what the
		specific row was optimising for.}
	\label{tab:final_results}\\
	
	\toprule
	& & \multicolumn{2}{c}{Recall} & \multicolumn{2}{c}{Precision} & & \\
	\cmidrule(lr){3-4} \cmidrule(lr){5-6}
	Base Classifier & Scorer & Added & Closed &
	Added & Closed & Accuracy & F1\\
	\midrule
	\endfirsthead
	
	\toprule
	& & \multicolumn{2}{c}{Recall} & \multicolumn{2}{c}{Precision} & & \\
	\cmidrule(lr){3-4} \cmidrule(lr){5-6}
	Base Classifier & Scorer & Added & Closed &
	Added & Closed & Accuracy & F1\\
	\midrule
	\endhead
	
	\midrule
	\multicolumn{8}{r}{\emph{Continued on next page}}\\
	\endfoot
	
	\bottomrule
	\endlastfoot
	
	\rowcolor{monoRow}
	LogisticRegression & recall\_closed & 0.797 & 0.676 & 0.945 & 0.321 & 0.695 
	& 0.457\\
	\rowcolor{empRow}
	LogisticRegression & recall\_closed & 0.789 & 0.336 & 0.186 & 0.892 & 0.409 
	& 0.301\\
	\rowcolor{catRow}
	LogisticRegression & recall\_closed & 0.992 & 0.048 & 0.167 & 0.969 & 
	\worstcell{0.200} & 0.286\\
	\rowcolor{monoRow}
	LogisticRegression & precision\_closed & 0.744 & 0.764 & 0.940 & 0.377 & 
	0.761 & 0.501\\
	\rowcolor{empRow}
	LogisticRegression & precision\_closed & 0.061 & 0.971 & 0.288 & 0.843 & 
	0.824 & 0.101\\
	\rowcolor{catRow}
	LogisticRegression & precision\_closed & 0.561 & 0.637 & 0.229 & 0.883 & 
	0.625 & 0.325\\
	\rowcolor{monoRow}
	LogisticRegression & recall\_add & 0.764 & 0.744 & 0.377 & 0.940 & 0.761 & 
	0.501\\
	\rowcolor{empRow}
	LogisticRegression & recall\_add & 0.977 & 0.053 & 0.843 & 0.302 & 0.828 & 
	0.090\\
	\rowcolor{catRow}
	LogisticRegression & recall\_add & 0.817 & 0.390 & 0.875 & 0.291 & 0.749 & 
	0.333\\
	\rowcolor{monoRow}
	LogisticRegression & precision\_add & 0.676 & 0.797 & 0.321 & 0.945 & 0.695 
	& 0.457\\
	\rowcolor{empRow}
	LogisticRegression & precision\_add & 0.675 & 0.431 & 0.861 & 0.203 & 0.636 
	& 0.276\\
	\rowcolor{catRow}
	LogisticRegression & precision\_add & 0.655 & 0.565 & 0.887 & 0.239 & 0.640 
	& 0.336\\
	\rowcolor{monoRow}
	LogisticRegression & accuracy & 0.744 & 0.764 & 0.940 & 0.377 & 0.761 & 
	0.501\\
	\rowcolor{empRow}
	LogisticRegression & accuracy & 0.081 & 0.966 & 0.312 & 0.846 & 0.823 & 
	0.129\\
	\rowcolor{catRow}
	LogisticRegression & accuracy & 0.398 & 0.805 & 0.282 & 0.874 & 0.739 & 
	0.330\\
	\rowcolor{monoRow}
	LogisticRegression & f1 & 0.744 & 0.764 & 0.940 & 0.377 & 0.761 & 0.501\\
	\rowcolor{empRow}
	LogisticRegression & f1 & 0.061 & 0.973 & 0.300 & 0.844 & 0.826 & 0.101\\
	\rowcolor{catRow}
	LogisticRegression & f1 & 0.659 & 0.578 & 0.230 & 0.898 & 0.591 & 0.341\\
	
	\rowcolor{monoRow}
	KNeighborsClassifier & recall\_closed & 0.789 & 0.721 & 0.947 & 0.351 & 
	0.731 & 0.486\\
	\rowcolor{empRow}
	KNeighborsClassifier & recall\_closed & 0.297 & 0.798 & 0.220 & 0.855 & 
	0.717 & 0.253\\
	\rowcolor{catRow}
	KNeighborsClassifier & recall\_closed & 0.671 & 0.521 & 0.212 & 0.892 & 
	0.545 & 0.322\\
	\rowcolor{monoRow}
	KNeighborsClassifier & precision\_closed & 0.724 & 0.884 & 0.943 & 0.546 & 
	0.859 & 0.622\\
	\rowcolor{empRow}
	KNeighborsClassifier & precision\_closed & 0.154 & 0.957 & 0.409 & 0.855 & 
	0.828 & 0.224\\
	\rowcolor{catRow}
	KNeighborsClassifier & precision\_closed & 0.504 & 0.737 & 0.269 & 0.886 & 
	0.699 & 0.351\\
	\rowcolor{monoRow}
	KNeighborsClassifier & recall\_add & 0.884 & 0.724 & 0.546 & 0.943 & 0.859 
	& 0.622\\
	\rowcolor{empRow}
	KNeighborsClassifier & recall\_add & 0.965 & 0.138 & 0.854 & 0.430 & 0.832 
	& 0.209\\
	\rowcolor{catRow}
	KNeighborsClassifier & recall\_add & 0.813 & 0.423 & 0.880 & 0.303 & 0.750 
	& 0.353\\
	\rowcolor{monoRow}
	KNeighborsClassifier & precision\_add & 0.800 & 0.789 & 0.431 & 0.952 & 
	0.798 & 0.557\\
	\rowcolor{empRow}
	KNeighborsClassifier & precision\_add & 0.859 & 0.289 & 0.863 & 0.283 & 
	0.768 & 0.286\\
	\rowcolor{catRow}
	KNeighborsClassifier & precision\_add & 0.521 & 0.703 & 0.901 & 0.220 & 
	0.551 & 0.335\\
	\rowcolor{monoRow}
	KNeighborsClassifier & accuracy & 0.724 & 0.884 & 0.943 & 0.546 & 0.859 & 
	0.622\\
	\rowcolor{empRow}
	KNeighborsClassifier & accuracy & 0.138 & 0.963 & 0.420 & 0.853 & 0.830 & 
	0.208\\
	\rowcolor{catRow}
	KNeighborsClassifier & accuracy & 0.423 & 0.801 & 0.290 & 0.878 & 0.740 & 
	0.344\\
	\rowcolor{monoRow}
	KNeighborsClassifier & f1 & 0.724 & 0.884 & 0.943 & 0.546 & 0.859 & 0.622\\
	\rowcolor{empRow}
	KNeighborsClassifier & f1 & 0.220 & 0.931 & 0.380 & 0.861 & 0.817 & 0.278\\
	\rowcolor{catRow}
	KNeighborsClassifier & f1 & 0.589 & 0.681 & 0.262 & 0.896 & 0.667 & 0.363\\
	
	\rowcolor{monoRow}
	GaussianNB & recall\_closed & 0.943 & 0.322 & 0.967 & 0.211 & 0.422 & 
	0.344\\
	\rowcolor{empRow}
	GaussianNB & recall\_closed & 0.232 & 0.858 & 0.238 & 0.853 & 0.757 & 
	0.235\\
	\rowcolor{catRow}
	GaussianNB & recall\_closed & 0.431 & 0.738 & 0.240 & 0.871 & 0.688 & 
	0.308\\
	\rowcolor{monoRow}
	GaussianNB & precision\_closed & 0.943 & 0.322 & 0.967 & 0.211 & 0.422 & 
	0.344\\
	\rowcolor{empRow}
	GaussianNB & precision\_closed & 0.232 & 0.858 & 0.238 & 0.853 & 0.757 & 
	0.235\\
	\rowcolor{catRow}
	GaussianNB & precision\_closed & 0.431 & 0.738 & 0.240 & 0.871 & 0.688 & 
	0.308\\
	\rowcolor{monoRow}
	GaussianNB & recall\_add & 0.322 & 0.943 & 0.211 & 0.967 & 0.422 & 0.344\\
	\rowcolor{empRow}
	GaussianNB & recall\_add & 0.858 & 0.232 & 0.853 & 0.238 & 0.757 & 0.235\\
	\rowcolor{catRow}
	GaussianNB & recall\_add & 0.738 & 0.431 & 0.871 & 0.240 & 0.688 & 0.308\\
	\rowcolor{monoRow}
	GaussianNB & precision\_add & 0.322 & 0.943 & 0.211 & 0.967 & 0.422 & 
	0.344\\
	\rowcolor{empRow}
	GaussianNB & precision\_add & 0.858 & 0.232 & 0.853 & 0.238 & 0.757 & 
	0.235\\
	\rowcolor{catRow}
	GaussianNB & precision\_add & 0.738 & 0.431 & 0.871 & 0.240 & 0.688 & 
	0.308\\
	\rowcolor{monoRow}
	GaussianNB & accuracy & 0.943 & 0.322 & 0.967 & 0.211 & 0.422 & 0.344\\
	\rowcolor{empRow}
	GaussianNB & accuracy & 0.232 & 0.858 & 0.238 & 0.853 & 0.757 & 0.235\\
	\rowcolor{catRow}
	GaussianNB & accuracy & 0.431 & 0.738 & 0.240 & 0.871 & 0.688 & 0.308\\
	\rowcolor{monoRow}
	GaussianNB & f1 & 0.943 & 0.322 & 0.967 & 0.211 & 0.422 & 0.344\\
	\rowcolor{empRow}
	GaussianNB & f1 & 0.232 & 0.858 & 0.238 & 0.853 & 0.757 & 0.235\\
	\rowcolor{catRow}
	GaussianNB & f1 & 0.431 & 0.738 & 0.240 & 0.871 & 0.688 & 0.308\\
	
	\rowcolor{monoRow}
	DecisionTreeClassifier & recall\_closed & 0.963 & 0.314 & 0.978 & 0.212 & 
	0.418 & 0.348\\
	\rowcolor{empRow}
	DecisionTreeClassifier & recall\_closed & 0.211 & 0.886 & 0.263 & 0.854 & 
	0.777 & 0.234\\
	\rowcolor{catRow}
	DecisionTreeClassifier & recall\_closed & 0.443 & 0.787 & 0.285 & 0.880 & 
	0.731 & 0.347\\
	\rowcolor{monoRow}
	DecisionTreeClassifier & precision\_closed & 0.610 & 0.899 & 0.923 & 0.538 
	& 0.853 & 0.571\\
	\rowcolor{empRow}
	DecisionTreeClassifier & precision\_closed & 0.008 & 0.998 & 0.500 & 0.840 
	& 0.839 & 0.016\\
	\rowcolor{catRow}
	DecisionTreeClassifier & precision\_closed & 0.033 & 0.989 & 0.364 & 0.842 
	& 0.835 & 0.060\\
	\rowcolor{monoRow}
	DecisionTreeClassifier & recall\_add & 0.904 & 0.622 & 0.554 & 0.926 & 
	0.859 & 0.586\\
	\rowcolor{empRow}
	DecisionTreeClassifier & recall\_add & 0.999 & 0.004 & 0.839 & 0.500 & 
	0.839 & 0.008\\
	\rowcolor{catRow}
	DecisionTreeClassifier & recall\_add & 0.995 & 0.024 & 0.842 & 0.500 & 
	0.839 & 0.047\\
	\rowcolor{monoRow}
	DecisionTreeClassifier & precision\_add & 0.314 & 0.963 & 0.212 & 0.978 & 
	0.418 & 0.348\\
	\rowcolor{empRow}
	DecisionTreeClassifier & precision\_add & 0.949 & 0.183 & 0.858 & 0.409 & 
	0.826 & 0.253\\
	\rowcolor{catRow}
	DecisionTreeClassifier & precision\_add & 0.863 & 0.293 & 0.864 & 0.290 & 
	0.771 & 0.291\\
	\rowcolor{monoRow}
	DecisionTreeClassifier & accuracy & 0.626 & 0.903 & 0.926 & 0.554 & 0.859 & 
	0.588\\
	\rowcolor{empRow}
	DecisionTreeClassifier & accuracy & 0.024 & 0.995 & 0.500 & 0.842 & 0.839 & 
	0.047\\
	\rowcolor{catRow}
	DecisionTreeClassifier & accuracy & 0.378 & 0.862 & 0.344 & 0.878 & 0.784 & 
	0.360\\
	\rowcolor{monoRow}
	DecisionTreeClassifier & f1 & 0.614 & 0.905 & 0.924 & 0.553 & 0.858 & 
	0.582\\
	\rowcolor{empRow}
	DecisionTreeClassifier & f1 & 0.004 & 0.998 & 0.333 & 0.839 & 0.838 & 
	0.008\\
	\rowcolor{catRow}
	DecisionTreeClassifier & f1 & 0.020 & 0.990 & 0.278 & 0.840 & 0.834 & 
	0.038\\
	
	\rowcolor{monoRow}
	RandomForestClassifier & recall\_closed & \bestcell{1.000} & 0.137 & 
	\bestcell{1.000} & 0.182 & 0.276 & 0.308\\
	\rowcolor{empRow}
	RandomForestClassifier & recall\_closed & 0.480 & 0.699 & 0.234 & 0.875 & 
	0.663 & 0.315\\
	\rowcolor{catRow}
	RandomForestClassifier & recall\_closed & 0.874 & 0.275 & 0.188 & 0.919 & 
	0.371 & 0.309\\
	\rowcolor{monoRow}
	RandomForestClassifier & precision\_closed & 0.585 & 0.951 & 0.923 & 0.696 
	& 0.892 & 0.636\\
	\rowcolor{empRow}
	RandomForestClassifier & precision\_closed & 0.008 & 0.999 & 0.667 & 0.840 
	& 0.840 & 0.016\\
	\rowcolor{catRow}
	RandomForestClassifier & precision\_closed & 0.220 & 0.971 & 0.593 & 0.866 
	& 0.850 & 0.320\\
	\rowcolor{monoRow}
	RandomForestClassifier & recall\_add & 0.952 & 0.585 & 0.702 & 0.923 & 
	0.893 & 0.639\\
	\rowcolor{empRow}
	RandomForestClassifier & recall\_add & \bestcell{1.000} & \worstcell{0.000} 
	& 0.839 & \worstcell{0.000} & 0.839 & \worstcell{0.000}\\
	\rowcolor{catRow}
	RandomForestClassifier & recall\_add & 0.987 & 0.134 & 0.856 & 0.660 & 
	0.849 & 0.223\\
	\rowcolor{monoRow}
	RandomForestClassifier & precision\_add & 0.166 & \bestcell{1.000} & 0.187 
	& \bestcell{1.000} & 0.301 & 0.315\\
	\rowcolor{empRow}
	RandomForestClassifier & precision\_add & 0.774 & 0.333 & 0.858 & 0.220 & 
	0.703 & 0.265\\
	\rowcolor{catRow}
	RandomForestClassifier & precision\_add & 0.578 & 0.683 & 0.905 & 0.237 & 
	0.595 & 0.352\\
	\rowcolor{monoRow}
	RandomForestClassifier & accuracy & 0.598 & 0.952 & 0.925 & 0.707 & 
	\bestcell{0.895} & \bestcell{0.648}\\
	\rowcolor{empRow}
	RandomForestClassifier & accuracy & \worstcell{0.000} & 0.999 & 
	\worstcell{0.000} & 0.839 & 0.838 & \worstcell{0.000}\\
	\rowcolor{catRow}
	RandomForestClassifier & accuracy & 0.142 & 0.985 & 0.648 & 0.857 & 0.849 & 
	0.233\\
	\rowcolor{monoRow}
	RandomForestClassifier & f1 & 0.618 & 0.927 & 0.927 & 0.620 & 0.878 & 
	0.619\\
	\rowcolor{empRow}
	RandomForestClassifier & f1 & 0.004 & \bestcell{1.000} & \bestcell{1.000} & 
	0.839 & 0.840 & 0.008\\
	\rowcolor{catRow}
	RandomForestClassifier & f1 & 0.293 & 0.889 & 0.336 & 0.867 & 0.793 & 
	0.313\\
	
	\rowcolor{monoRow}
	HistGradientBoostingClassifier & recall\_closed & 0.935 & 0.375 & 0.968 & 
	0.223 & 0.466 & 0.361\\
	\rowcolor{empRow}
	HistGradientBoostingClassifier & recall\_closed & 0.268 & 0.835 & 0.238 & 
	0.856 & 0.744 & 0.252\\
	\rowcolor{catRow}
	HistGradientBoostingClassifier & recall\_closed & 0.573 & 0.615 & 0.222 & 
	0.882 & 0.608 & 0.320\\
	\rowcolor{monoRow}
	HistGradientBoostingClassifier & precision\_closed & 0.687 & 0.834 & 0.933 
	& 0.442 & 0.810 & 0.538\\
	\rowcolor{empRow}
	HistGradientBoostingClassifier & precision\_closed & 0.024 & 0.990 & 0.316 
	& 0.841 & 0.834 & 0.045\\
	\rowcolor{catRow}
	HistGradientBoostingClassifier & precision\_closed & 0.305 & 0.898 & 0.364 
	& 0.871 & 0.802 & 0.332\\
	\rowcolor{monoRow}
	HistGradientBoostingClassifier & recall\_add & 0.834 & 0.687 & 0.442 & 
	0.933 & 0.810 & 0.538\\
	\rowcolor{empRow}
	HistGradientBoostingClassifier & recall\_add & 0.998 & 0.020 & 0.841 & 
	0.625 & 0.840 & 0.039\\
	\rowcolor{catRow}
	HistGradientBoostingClassifier & recall\_add & 0.903 & 0.297 & 0.870 & 
	0.371 & 0.806 & 0.330\\
	\rowcolor{monoRow}
	HistGradientBoostingClassifier & precision\_add & 0.375 & 0.935 & 0.223 & 
	0.968 & 0.466 & 0.361\\
	\rowcolor{empRow}
	HistGradientBoostingClassifier & precision\_add & 0.904 & 0.203 & 0.855 & 
	0.289 & 0.791 & 0.239\\
	\rowcolor{catRow}
	HistGradientBoostingClassifier & precision\_add & 0.703 & 0.480 & 0.876 & 
	0.237 & 0.667 & 0.317\\
	\rowcolor{monoRow}
	HistGradientBoostingClassifier & accuracy & 0.687 & 0.834 & 0.933 & 0.442 & 
	0.810 & 0.538\\
	\rowcolor{empRow}
	HistGradientBoostingClassifier & accuracy & 0.024 & 0.992 & 0.375 & 0.841 & 
	0.836 & 0.046\\
	\rowcolor{catRow}
	HistGradientBoostingClassifier & accuracy & 0.297 & 0.903 & 0.371 & 0.870 & 
	0.806 & 0.330\\
	\rowcolor{monoRow}
	HistGradientBoostingClassifier & f1 & 0.687 & 0.834 & 0.933 & 0.442 & 0.810 
	& 0.538\\
	\rowcolor{empRow}
	HistGradientBoostingClassifier & f1 & 0.130 & 0.958 & 0.372 & 0.851 & 0.824 
	& 0.193\\
	\rowcolor{catRow}
	HistGradientBoostingClassifier & f1 & 0.350 & 0.856 & 0.319 & 0.873 & 0.775 
	& 0.333\\
	
	\rowcolor{monoRow}
	XGBClassifier & recall\_closed & 0.858 & 0.593 & 0.956 & 0.288 & 0.636 & 
	0.431\\
	\rowcolor{empRow}
	XGBClassifier & recall\_closed & 0.041 & 0.988 & 0.385 & 0.843 & 0.835 & 
	0.074\\
	\rowcolor{catRow}
	XGBClassifier & recall\_closed & 0.431 & 0.831 & 0.329 & 0.884 & 0.767 & 
	0.373\\
	\rowcolor{monoRow}
	XGBClassifier & precision\_closed & 0.744 & 0.828 & 0.944 & 0.454 & 0.815 & 
	0.564\\
	\rowcolor{empRow}
	XGBClassifier & precision\_closed & \worstcell{0.000} & 0.999 & 
	\worstcell{0.000} & 0.839 & 0.838 & \worstcell{0.000}\\
	\rowcolor{catRow}
	XGBClassifier & precision\_closed & 0.012 & 0.998 & 0.600 & 0.840 & 0.840 & 
	0.024\\
	\rowcolor{monoRow}
	XGBClassifier & recall\_add & 0.828 & 0.744 & 0.454 & 0.944 & 0.815 & 
	0.564\\
	\rowcolor{empRow}
	XGBClassifier & recall\_add & 0.998 & 0.008 & 0.840 & 0.500 & 0.839 & 
	0.016\\
	\rowcolor{catRow}
	XGBClassifier & recall\_add & 0.998 & 0.020 & 0.841 & 0.625 & 0.840 & 
	0.039\\
	\rowcolor{monoRow}
	XGBClassifier & precision\_add & 0.593 & 0.858 & 0.288 & 0.956 & 0.636 & 
	0.431\\
	\rowcolor{empRow}
	XGBClassifier & precision\_add & 0.994 & 0.033 & 0.842 & 0.500 & 0.839 & 
	0.061\\
	\rowcolor{catRow}
	XGBClassifier & precision\_add & 0.991 & 0.045 & 0.844 & 0.478 & 0.838 & 
	0.082\\
	\rowcolor{monoRow}
	XGBClassifier & accuracy & 0.744 & 0.828 & 0.944 & 0.454 & 0.815 & 0.564\\
	\rowcolor{empRow}
	XGBClassifier & accuracy & \worstcell{0.000} & 0.998 & \worstcell{0.000} & 
	0.839 & 0.838 & \worstcell{0.000}\\
	\rowcolor{catRow}
	XGBClassifier & accuracy & 0.016 & 0.998 & 0.667 & 0.841 & 0.840 & 0.032\\
	\rowcolor{monoRow}
	XGBClassifier & f1 & 0.744 & 0.828 & 0.944 & 0.454 & 0.815 & 0.564\\
	\rowcolor{empRow}
	XGBClassifier & f1 & 0.004 & 0.999 & 0.500 & 0.839 & 0.839 & 0.008\\
	\rowcolor{catRow}
	XGBClassifier & f1 & 0.012 & 0.997 & 0.429 & 0.840 & 0.838 & 0.024\\
	
	\rowcolor{monoRow}
	LGBMClassifier & recall\_closed & 0.760 & 0.763 & 0.943 & 0.382 & 0.763 & 
	0.508\\
	\rowcolor{empRow}
	LGBMClassifier & recall\_closed & 0.057 & 0.949 & 0.177 & 0.840 & 0.806 & 
	0.086\\
	\rowcolor{catRow}
	LGBMClassifier & recall\_closed & 0.565 & 0.694 & 0.262 & 0.893 & 0.673 & 
	0.358\\
	\rowcolor{monoRow}
	LGBMClassifier & precision\_closed & 0.715 & 0.821 & 0.938 & 0.435 & 0.804 
	& 0.541\\
	\rowcolor{empRow}
	LGBMClassifier & precision\_closed & 0.098 & 0.956 & 0.300 & 0.847 & 0.818 
	& 0.147\\
	\rowcolor{catRow}
	LGBMClassifier & precision\_closed & 0.549 & 0.706 & 0.264 & 0.891 & 0.681 
	& 0.357\\
	\rowcolor{monoRow}
	LGBMClassifier & recall\_add & 0.821 & 0.715 & 0.435 & 0.938 & 0.804 & 
	0.541\\
	\rowcolor{empRow}
	LGBMClassifier & recall\_add & 0.956 & 0.093 & 0.846 & 0.291 & 0.817 & 
	0.142\\
	\rowcolor{catRow}
	LGBMClassifier & recall\_add & 0.708 & 0.549 & 0.891 & 0.265 & 0.682 & 
	0.358\\
	\rowcolor{monoRow}
	LGBMClassifier & precision\_add & 0.763 & 0.760 & 0.382 & 0.943 & 0.763 & 
	0.508\\
	\rowcolor{empRow}
	LGBMClassifier & precision\_add & 0.945 & 0.065 & 0.840 & 0.184 & 0.803 & 
	0.096\\
	\rowcolor{catRow}
	LGBMClassifier & precision\_add & 0.694 & 0.565 & 0.893 & 0.262 & 0.673 & 
	0.358\\
	\rowcolor{monoRow}
	LGBMClassifier & accuracy & 0.715 & 0.821 & 0.938 & 0.435 & 0.804 & 0.541\\
	\rowcolor{empRow}
	LGBMClassifier & accuracy & 0.093 & 0.950 & 0.264 & 0.845 & 0.812 & 0.138\\
	\rowcolor{catRow}
	LGBMClassifier & accuracy & 0.549 & 0.706 & 0.264 & 0.891 & 0.681 & 0.357\\
	\rowcolor{monoRow}
	LGBMClassifier & f1 & 0.715 & 0.821 & 0.938 & 0.435 & 0.804 & 0.541\\
	\rowcolor{empRow}
	LGBMClassifier & f1 & 0.065 & 0.945 & 0.184 & 0.840 & 0.803 & 0.096\\
	\rowcolor{catRow}
	LGBMClassifier & f1 & 0.565 & 0.694 & 0.262 & 0.893 & 0.673 & 0.358\\
	
\end{longtable}



\subsection{Machine Learning Frameworks}
\hltodo{A}{move whole subsection to appendix}fter data analysis and 
cleanup, the next step is 
choosing a machine learning 
framework to develop a model with. Since the primary focus is on 
classification, most modern frameworks already provide the needed libraries, 
tools, and implementations for this task. The chosen framework should 
also provide tools for data preprocessing and result evaluation.

There are several available frameworks in Python that can be used for machine 
learning, and they all provide various methods such as decision trees, support 
vector machines, or even linear models. These options include, among others, 
Scikit-learn~\cite{scikitlearn}, 
Tensorflow~\cite{TensorFlow}, and 
PyTorch~\cite{PyTorch}. Each framework has its own strengths and weaknesses. 
PyTorch and Tensorflow display great applicability within deep learning and 
\glspl{nn}, offering varying levels of scalability and 
ease-of-deployment~\cite{choosingMLFramework}. However, due to the simplicity 
and smaller 
amounts of data available to us, as well as the focus on more 
traditional \gls{ml} approaches, we decided to utilize the scikit-learn 
library for constructing the classifiers for this paper.